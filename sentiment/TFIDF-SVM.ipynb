{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + SVM 을 이용한 News Sentiment 분석\n",
    "## Process\n",
    "1. 미리 Preprocessing된 데이터를 읽어\n",
    "2. 데이터를 TF-IDF로 임베딩\n",
    "3. TRAIN-TEST 데이터 분리\n",
    "4. SVM으로 TRAIN 학습\n",
    "5. TEST 검증\n",
    "6. 최적의 k값 찾기\n",
    "\n",
    "## Reference\n",
    "- [Word Embedding Explained, a comparison and code tutorial](https://medium.com/@dcameronsteinke/tf-idf-vs-word-embedding-a-comparison-and-code-tutorial-5ba341379ab0)\n",
    "- [Scikit-Learn의 문서 전처리 기능](https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/)\n",
    "- [서포트 벡터 머신](https://datascienceschool.net/view-notebook/6c6d450cb2ee49558856fd924b326e00/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_token</th>\n",
       "      <th>content_token</th>\n",
       "      <th>reaction_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]</td>\n",
       "      <td>[대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[식약처, 존슨, 앤드, 존슨, 제품, 빼고, 암, 위험, 인공, 유방, 퇴, 출,...</td>\n",
       "      <td>[식품의약품안전처, 암, 발병, 사례, 보고, 된, 인공, 유방, 보, 형, 물이,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...</td>\n",
       "      <td>[주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[비서, 성폭행, 안희정, 심, 달랐던, 판단, 오늘, 대법, 선고, 네이버, 뉴스]</td>\n",
       "      <td>[앵커, 심, 무죄, 나왔지만, 심, 실형, 선고, 받고, 법정구속, 돼, 있습니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[인천, 경기, 북부, 호우, 주의보, 내일, 최고, 더, 온다, 네이버, 뉴스]</td>\n",
       "      <td>[아침, 인천, 경기, 북부, 파주, 고양, 연천, 김포, 안산, 호우, 주의보, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_token  \\\n",
       "0      [전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]   \n",
       "1     [식약처, 존슨, 앤드, 존슨, 제품, 빼고, 암, 위험, 인공, 유방, 퇴, 출,...   \n",
       "10    [늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...   \n",
       "100     [비서, 성폭행, 안희정, 심, 달랐던, 판단, 오늘, 대법, 선고, 네이버, 뉴스]   \n",
       "1000      [인천, 경기, 북부, 호우, 주의보, 내일, 최고, 더, 온다, 네이버, 뉴스]   \n",
       "\n",
       "                                          content_token  reaction_category  \n",
       "0     [대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...                  1  \n",
       "1     [식품의약품안전처, 암, 발병, 사례, 보고, 된, 인공, 유방, 보, 형, 물이,...                  1  \n",
       "10    [주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...                  2  \n",
       "100   [앵커, 심, 무죄, 나왔지만, 심, 실형, 선고, 받고, 법정구속, 돼, 있습니다...                  1  \n",
       "1000  [아침, 인천, 경기, 북부, 파주, 고양, 연천, 김포, 안산, 호우, 주의보, ...                  2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러옴\n",
    "data = pd.read_json(\"../data/news_reactions_recent_preprocessed.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Scikit-Learn의 TfidVectorizer를 이용해서 TF-IDF 임베딩을 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes: 512, 1024, 2048, 5096, 10192, 20384\n",
    "MAX_FEATURE = 10192\n",
    "title_vectorizer = TfidfVectorizer (max_features=MAX_FEATURE)\n",
    "content_vectorizer = TfidfVectorizer (max_features=MAX_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.1 ms, sys: 3.86 ms, total: 77 ms\n",
      "Wall time: 76.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "title_corpus = data.title_token.map(lambda x: \" \".join(x))\n",
    "title_vectorizer.fit(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 947 ms, sys: 26.9 ms, total: 974 ms\n",
      "Wall time: 999 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "content_corpus = data.content_token.map(lambda x: \" \".join(x))\n",
    "content_vectorizer.fit(content_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 생성한 Vectorizer를 이용해서 문장 내의 토큰들을 TF-IDF 벡터로 변환한다.\n",
    "그러면 한 뉴스 문서는 TF-IDF 벡터들의 목록이므로 2차원 배열이 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 725 ms, sys: 4.57 ms, total: 730 ms\n",
      "Wall time: 731 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "TITLE_MAX_LEN = 32\n",
    "CONTENT_MAX_LEN = 512\n",
    "# title_X = data.title_token.map(lambda x: title_vectorizer.transform(x if len(x) <= TITLE_MAX_LEN else x[:TITLE_MAX_LEN]))\n",
    "# content_X = data.title_token.map(lambda x: content_vectorizer.transform(x if len(x) <= CONTENT_MAX_LEN else x[:CONTENT_MAX_LEN]))\n",
    "title_X = title_vectorizer.transform(title_corpus)\n",
    "content_X = content_vectorizer.transform(content_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전두환 프로젝트 연희동 집 가구 세트 막대 세금 구입 네이버 뉴스 36   (0, 5641)\t0.3211966419109778\n",
      "  (0, 4488)\t0.37196786430038203\n",
      "  (0, 3717)\t0.37196786430038203\n",
      "  (0, 2949)\t0.35322971674164627\n",
      "  (0, 2931)\t0.35322971674164627\n",
      "  (0, 1761)\t0.37196786430038203\n",
      "  (0, 1182)\t0.04621395820263048\n",
      "  (0, 1087)\t0.04621395820263048\n",
      "  (0, 657)\t0.35322971674164627\n",
      "  (0, 126)\t0.3211966419109778\n",
      "대통령 자리 물러난 전두환 별도 전직 대통령 사무실 내지 않았으면서도 사무실 임차보증금 월세 등 명목 정부 원금 받아 간 사실 문서 확인 됐다 또 퇴임 후 서울 서대문구 연희동 집 돌아간 전두환 막대 세금 각종 고급 가구 등 구입 해 자신 집 꾸민 사실 드러났다 뉴스타파 행정안전부 제출 받은 전직 대통령 예 우 관련 더미 이 같은 사실 보여주는 정부 문서 찾아냈다 뉴스타파 확인 문서 총무처 현 행정안전부 생산 된 것 문서 따르면 전두환 퇴임 후 본인 집 사무실 차리겠다며 임차보증금 원 월세 관리 비조 매달 원 정도 정부 받아 챙겼다 자기 집 자신 세 놓는 형태 나랏돈 빼 먹은 것 뉴스타파 행정안전부 정보공개 청구 해 작성 된 전직 대통령 예 우 관련 문서 확보 했다 전직 대통령 전두환 지급 된 역 확인 하기 위 해서다 뉴스타파 입수 문서 지금 행정안전부 해당 하는 총무처 만든 것 작성 당시 총무처 장관 이었던 김용갑 씨 결재 문서 군인 출신 김용갑 씨 전두환 정부 민정 수석 지낸 뒤 노태우 정부 총무처 장관 지냈다 총무처 문서 전두환 퇴임 직후 정부 지원 받은 내 역 빼곡 히 들어있다 그 중 사무 집기 항목 보면 책상 원 의자 원 응접실 세트 원 가 들어 있고 심지어 옷 걸이 기정 화기 시계 정부 예산 사들인 것 나온다 이런 식 전두환 자신 연희동 집 꾸미는 데 사용 예산 당시 돈 원 넘었다 같은 시기 전두환 비서 받은 월급 원 불과했다 전두환 사무실 집기 사들이는 비용 외 건물 임대료 명목 돈 정부 받아 냈다 대통령 퇴임 후 외부 사무실 내지 않고 본인 사는 집 전직 대통령 사무실 로 꾸몄으면서도 사무실 임차보증금 원 과 월세 원 등 별도 받아 간 것 뉴스타파 전두환 퇴임 이후 각종 명목 챙겨 간 원금 규모 당시 물가 비교 해 봤다 먼저 당시 서울 아파트 시세 기사 따르면 서울 노원구 평형 아파트 분양 가는 원 정도 였다 전두환 있지도 않은 사무실 임대 보증금 원 과 사무실 집기 구입 비용 원 챙긴 금액 비슷했다 정부 발표 공무원 월급 비교 해 봤다 동아일보 보도 따르면 최고 위 직인 급 공무원 기본 급 원 급 사무관 원 정도 였다 결국 전두환 급 공무원 월급 배 가까운 세금 여 원 받아 자기 집 각종 집기 마련 매달 사무관 월급 배 월 여 원 달 하는 국민 세금 존재 하지도 않는 사무실 운영 비라며 받아 간 것 전두환 이렇게 세금 받아가던 전두환 동생 전경환 씨 새마을 비리 사업 구속 되고 이어 국회 비리 특별 위원회 가 구성 되는 등 비리 대한 국민 적 분노 치솟던 때 였다 그럼 전두환 이외 다른 대통령 들 전직 대통령 예 우 따른 사무실 운영 비 어떻게 받아 갔을까 취재 진 행정안전부 물어봤다 노무현 이명박 김대중 김영삼 대통령 경우 행정안전부 저 집기 같은 걸 지원 사례 없습니다 전직 대통령 법률 따라 사무실 운영 경비 국가 로부터 지원 받을 수 있는데 행정안전부 그 동안 이를 정액 지급 해 왔습니다 행정안전부 관계자 행정안전부 설명 종합 하면 전직 대통령 전직 대통령 예 우 관 법률 따라 매년 정해진 금액 사무실 운영 비 지원 했다 전두환 사례 사무실 아닌 자기 집 쓸 책상 의자 하나 하나 청구 해 받아 간 사례 없었다는 것 전두환 퇴 임하기 직전 당시 여당 이었던 민정당 느닷없이 전직 대통령 예우 관 법률 개정안 발의 했다 전직 대통령 대한 우의 규모 범위 대폭 확대 내용 이었다 먼저 퇴임후 지급 받는 대통령 연금 지급 방식 고쳤다 대통령 봉급 액 를 연금 주던 것 봉급 액 각종 수당 포함 금액 를 주는 식 상향 조정 했다 그 결과 당시 전두환 금액 증액 됐다 또 전직 대통령 사무실 운영 비 국가 예산 지원 하도록 했다 기존 교통 통신 편의 지원 정도 였던 것 사무실 운영 비 차량 등 운영 비 지급 바꾼 것 또 생존 기간 내내 국가 경호 받게 했다 군사 쿠데타 광주 학살 정권 잡았고 임기 내내 부정부패 았 것 모자라 퇴임 이후 삶 세금 꼼꼼히 챙겼던 전두환 비리 광주 학살 주도한 혐의 무기징역 함께 원 추징 금 선고 받았던 전두환 넘은 지금 원 넘는 추징 금 내지 않고 버티고 있다 뉴스타파 강민수 기자 한국 탐사저널리즘 센터 뉴스타파 진실 함께 지켜주세요 여러분 제보 세상 바꿀 수 있습니다 2050   (0, 10052)\t0.031045808872446755\n",
      "  (0, 10045)\t0.014355610760603866\n",
      "  (0, 10042)\t0.013792058450728666\n",
      "  (0, 9954)\t0.01746961114322843\n",
      "  (0, 9933)\t0.01253150397520167\n",
      "  (0, 9872)\t0.23314311640957705\n",
      "  (0, 9835)\t0.031303846607917005\n",
      "  (0, 9775)\t0.024260529945876377\n",
      "  (0, 9751)\t0.012779885933885128\n",
      "  (0, 9725)\t0.025627714197973325\n",
      "  (0, 9689)\t0.02002168843783266\n",
      "  (0, 9637)\t0.0080142625328065\n",
      "  (0, 9618)\t0.05835361451443863\n",
      "  (0, 9601)\t0.025367440820281573\n",
      "  (0, 9562)\t0.01019847591669125\n",
      "  (0, 9545)\t0.016733936598691452\n",
      "  (0, 9526)\t0.010851466544537527\n",
      "  (0, 9514)\t0.02597332170222183\n",
      "  (0, 9500)\t0.009810803728009257\n",
      "  (0, 9373)\t0.012916623475731243\n",
      "  (0, 9339)\t0.02809786518465019\n",
      "  (0, 9308)\t0.021587888363561732\n",
      "  (0, 9212)\t0.017122886818176662\n",
      "  (0, 9175)\t0.15220464492168945\n",
      "  (0, 9150)\t0.016503594989217055\n",
      "  :\t:\n",
      "  (0, 1144)\t0.022324021865137832\n",
      "  (0, 1118)\t0.04006525621513163\n",
      "  (0, 1102)\t0.04708666806975875\n",
      "  (0, 1096)\t0.020173369608838518\n",
      "  (0, 1094)\t0.015481991944561284\n",
      "  (0, 1067)\t0.01888217310853861\n",
      "  (0, 1030)\t0.040653428669090524\n",
      "  (0, 997)\t0.014473779575492191\n",
      "  (0, 994)\t0.017390647194939778\n",
      "  (0, 989)\t0.010410155207489386\n",
      "  (0, 906)\t0.0647636650906852\n",
      "  (0, 805)\t0.021914110747694674\n",
      "  (0, 743)\t0.009797345422637412\n",
      "  (0, 733)\t0.024889927379889258\n",
      "  (0, 703)\t0.026862789691311756\n",
      "  (0, 690)\t0.013724447669194983\n",
      "  (0, 688)\t0.010568011073978029\n",
      "  (0, 601)\t0.01830889668148721\n",
      "  (0, 534)\t0.02128471331368179\n",
      "  (0, 499)\t0.02840304952315053\n",
      "  (0, 447)\t0.03062134848322597\n",
      "  (0, 362)\t0.06113827538011507\n",
      "  (0, 257)\t0.017197552976643934\n",
      "  (0, 252)\t0.0194158075558924\n",
      "  (0, 249)\t0.020025313699196825\n"
     ]
    }
   ],
   "source": [
    "print(title_corpus[0], len(title_corpus[0]), title_X[0])\n",
    "print(content_corpus[0], len(content_corpus[0]), content_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2302, 6078)\n",
      "(2302, 10192)\n"
     ]
    }
   ],
   "source": [
    "print(title_X.shape)\n",
    "print(content_X.shape)\n",
    "# sparse matrix로 결과가 나오는 모습이다\n",
    "# print(title_X[0].shape)\n",
    "# print(title_X[0].toarray())\n",
    "# print(content_X[0].shape)\n",
    "# print(content_X[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302 0       1\n",
      "1       1\n",
      "10      2\n",
      "100     1\n",
      "1000    2\n",
      "Name: reaction_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = data.reaction_category\n",
    "print(len(y), y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# add padding and merge title and content\n",
    "def add_padding(x, min_size):\n",
    "    if len(x) <= min_size:\n",
    "        pad = np.zeros((min_size - len(x), x.shape[1]), dtype=float)\n",
    "        return np.concatenate([x, pad], axis=0)\n",
    "    elif len(x) > min_size:\n",
    "        return x[:min_size]\n",
    "    return x\n",
    "\n",
    "# a = title_X[0]\n",
    "# r = add_padding(a.toarray(), TITLE_MAX_LEN)\n",
    "# print(r)\n",
    "# print(r.shape)\n",
    "title_X = np.array(list(map(lambda x: add_padding(x.toarray(), TITLE_MAX_LEN), title_X)))\n",
    "content_X = np.array(list(map(lambda x: add_padding(x.toarray(), CONTENT_MAX_LEN), content_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_X = np.asarray(title_X)\n",
    "# content_X = np.asarray(content_X)\n",
    "print(title_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a1b84c6ac551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 뉴스 제목이랑 뉴스 내용이랑 합친다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 메모리없어서 자꾸 터짐 ㅠ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtitle_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "# 뉴스 제목이랑 뉴스 내용이랑 합친다.\n",
    "X = [np.concatenate([title_X[i], content_X[i]], axis=0) for i in range(len(title_X))]\n",
    "\n",
    "# 메모리없어서 자꾸 터짐 ㅠ\n",
    "del title_X\n",
    "del content_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (544, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Shape check\n",
    "print(len(X))\n",
    "print(X[0], X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하기\n",
    "sklearn.svm.SVM을 이용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn은 학습데이터가 2d array여야해서 강제로 변경\n",
    "nsamples = len(X)\n",
    "nx, ny = X[0].shape\n",
    "X = np.reshape(X, (nsamples, nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 실험 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 SVC를 이용해서 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 9.32 s, sys: 17.2 s, total: 26.5 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model = LinearSVC(verbose=1, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score() 함수를 이용해서 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544468546637744"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 결과의 몇개 예시를 만들어본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_token           [전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]\n",
      "content_token        [대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...\n",
      "reaction_category                                                    1\n",
      "Name: 0, dtype: object\n",
      "Predict: 부정\n",
      "Answer: 부정\n",
      "\n",
      "title_token          [늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...\n",
      "content_token        [주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...\n",
      "reaction_category                                                    2\n",
      "Name: 10, dtype: object\n",
      "Predict: 중립\n",
      "Answer: 중립\n",
      "\n",
      "title_token                    [검찰, 없는, 컬러, 표창장, 박지원, 입수, 경로, 네이버, 뉴스]\n",
      "content_token        [꿈, 담는, 캔버스, 채널, A, CHANNEL, A, 무단, 재, 및, 재, 배...\n",
      "reaction_category                                                    1\n",
      "Name: 50, dtype: object\n",
      "Predict: 긍정\n",
      "Answer: 부정\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_i = [0, 10, 50]\n",
    "sentiment = [\"긍정\", \"부정\", \"중립\"]\n",
    "for i in test_i:\n",
    "    x = X_test[i]\n",
    "    y = model.predict([x])[0]\n",
    "    print(data.loc[i])\n",
    "    print(\"Predict:\", sentiment[y])\n",
    "    print(\"Answer:\", sentiment[y_test.values[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 모델을 pickle 파일로 저장합니다.\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "t = datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "pickle.dump(model, open(f\"../model/tfidf_svm_{t}.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
