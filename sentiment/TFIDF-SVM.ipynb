{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + SVM 을 이용한 News Sentiment 분석\n",
    "## Process\n",
    "1. 미리 Preprocessing된 데이터를 읽어\n",
    "2. 데이터를 TF-IDF로 임베딩\n",
    "3. TRAIN-TEST 데이터 분리\n",
    "4. SVM으로 TRAIN 학습\n",
    "5. TEST 검증\n",
    "6. 최적의 k값 찾기\n",
    "\n",
    "## Reference\n",
    "- [Word Embedding Explained, a comparison and code tutorial](https://medium.com/@dcameronsteinke/tf-idf-vs-word-embedding-a-comparison-and-code-tutorial-5ba341379ab0)\n",
    "- [Scikit-Learn의 문서 전처리 기능](https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/)\n",
    "- [서포트 벡터 머신](https://datascienceschool.net/view-notebook/6c6d450cb2ee49558856fd924b326e00/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_token</th>\n",
       "      <th>content_token</th>\n",
       "      <th>reaction_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]</td>\n",
       "      <td>[대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[식약처, 존슨, 앤드, 존슨, 제품, 빼고, 암, 위험, 인공, 유방, 퇴, 출,...</td>\n",
       "      <td>[식품의약품안전처, 암, 발병, 사례, 보고, 된, 인공, 유방, 보, 형, 물이,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...</td>\n",
       "      <td>[주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[비서, 성폭행, 안희정, 심, 달랐던, 판단, 오늘, 대법, 선고, 네이버, 뉴스]</td>\n",
       "      <td>[앵커, 심, 무죄, 나왔지만, 심, 실형, 선고, 받고, 법정구속, 돼, 있습니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[인천, 경기, 북부, 호우, 주의보, 내일, 최고, 더, 온다, 네이버, 뉴스]</td>\n",
       "      <td>[아침, 인천, 경기, 북부, 파주, 고양, 연천, 김포, 안산, 호우, 주의보, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_token  \\\n",
       "0      [전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]   \n",
       "1     [식약처, 존슨, 앤드, 존슨, 제품, 빼고, 암, 위험, 인공, 유방, 퇴, 출,...   \n",
       "10    [늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...   \n",
       "100     [비서, 성폭행, 안희정, 심, 달랐던, 판단, 오늘, 대법, 선고, 네이버, 뉴스]   \n",
       "1000      [인천, 경기, 북부, 호우, 주의보, 내일, 최고, 더, 온다, 네이버, 뉴스]   \n",
       "\n",
       "                                          content_token  reaction_category  \n",
       "0     [대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...                  1  \n",
       "1     [식품의약품안전처, 암, 발병, 사례, 보고, 된, 인공, 유방, 보, 형, 물이,...                  1  \n",
       "10    [주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...                  2  \n",
       "100   [앵커, 심, 무죄, 나왔지만, 심, 실형, 선고, 받고, 법정구속, 돼, 있습니다...                  1  \n",
       "1000  [아침, 인천, 경기, 북부, 파주, 고양, 연천, 김포, 안산, 호우, 주의보, ...                  2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러옴\n",
    "data = pd.read_json(\"../data/news_reactions_recent_preprocessed.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Scikit-Learn의 TfidVectorizer를 이용해서 TF-IDF 임베딩을 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURE = 2048\n",
    "title_vectorizer = TfidfVectorizer (max_features=MAX_FEATURE)\n",
    "content_vectorizer = TfidfVectorizer (max_features=MAX_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.7 ms, sys: 19.8 ms, total: 82.4 ms\n",
      "Wall time: 88.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "title_corpus = data.title_token.map(lambda x: \" \".join(x))\n",
    "title_vectorizer.fit(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 892 ms, sys: 182 ms, total: 1.07 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "content_corpus = data.content_token.map(lambda x: \" \".join(x))\n",
    "content_vectorizer.fit(content_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 생성한 Vectorizer를 이용해서 문장 내의 토큰들을 TF-IDF 벡터로 변환한다.\n",
    "그러면 한 뉴스 문서는 TF-IDF 벡터들의 목록이므로 2차원 배열이 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 30.4 ms, total: 2.31 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "TITLE_MAX_LEN = 32\n",
    "CONTENT_MAX_LEN = 512\n",
    "title_X = data.title_token.map(lambda x: title_vectorizer.transform(x if len(x) <= TITLE_MAX_LEN else x[:TITLE_MAX_LEN]))\n",
    "content_X = data.title_token.map(lambda x: content_vectorizer.transform(x if len(x) <= CONTENT_MAX_LEN else x[:CONTENT_MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(title_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2048)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(11, 2048)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix로 결과가 나오는 모습이다\n",
    "print(title_X[0].shape)\n",
    "print(title_X[0].toarray())\n",
    "print(content_X[0].shape)\n",
    "print(content_X[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302 0       1\n",
      "1       1\n",
      "10      2\n",
      "100     1\n",
      "1000    2\n",
      "Name: reaction_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = data.reaction_category\n",
    "print(len(y), y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 12 s, total: 22.3 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# add padding and merge title and content\n",
    "def add_padding(x, min_size):\n",
    "    if len(x) <= min_size:\n",
    "        pad = np.zeros((min_size - len(x), x.shape[1]), dtype=float)\n",
    "        return np.concatenate([x, pad], axis=0)\n",
    "    return x\n",
    "\n",
    "# a = title_X[0]\n",
    "# r = add_padding(a.toarray(), TITLE_MAX_LEN)\n",
    "# print(r)\n",
    "# print(r.shape)\n",
    "title_X = title_X.map(lambda x: add_padding(x.toarray(), TITLE_MAX_LEN))\n",
    "content_X = content_X.map(lambda x: add_padding(x.toarray(), CONTENT_MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_X = np.asarray(title_X)\n",
    "content_X = np.asarray(content_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 제목이랑 뉴스 내용이랑 합친다.\n",
    "X = [np.concatenate([title_X[i], content_X[i]], axis=0) for i in range(len(title_X))]\n",
    "\n",
    "# 메모리없어서 자꾸 터짐 ㅠ\n",
    "del title_X\n",
    "del content_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (544, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Shape check\n",
    "print(len(X))\n",
    "print(X[0], X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하기\n",
    "sklearn.svm.SVM을 이용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn은 학습데이터가 2d array여야해서 강제로 변경\n",
    "nsamples = len(X)\n",
    "nx, ny = X[0].shape\n",
    "X = np.reshape(X, (nsamples, nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 실험 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 SVC를 이용해서 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 9.32 s, sys: 17.2 s, total: 26.5 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model = LinearSVC(verbose=1, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score() 함수를 이용해서 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544468546637744"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 결과의 몇개 예시를 만들어본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_token           [전두환, 프로젝트, 연희동, 집, 가구, 세트, 막대, 세금, 구입, 네이버, 뉴스]\n",
      "content_token        [대통령, 자리, 물러난, 전두환, 별도, 전직, 대통령, 사무실, 내지, 않았으면...\n",
      "reaction_category                                                    1\n",
      "Name: 0, dtype: object\n",
      "Predict: 부정\n",
      "Answer: 부정\n",
      "\n",
      "title_token          [늘어나는, 주택연금, 가입자, 집, 한, 채, 있다면, 노후, 걱정, 마세요, 네...\n",
      "content_token        [주택연금, 올, 들어서만, 명, 가입, 정부, 주택연금, 가입, 기준, 완화, 예...\n",
      "reaction_category                                                    2\n",
      "Name: 10, dtype: object\n",
      "Predict: 중립\n",
      "Answer: 중립\n",
      "\n",
      "title_token                    [검찰, 없는, 컬러, 표창장, 박지원, 입수, 경로, 네이버, 뉴스]\n",
      "content_token        [꿈, 담는, 캔버스, 채널, A, CHANNEL, A, 무단, 재, 및, 재, 배...\n",
      "reaction_category                                                    1\n",
      "Name: 50, dtype: object\n",
      "Predict: 긍정\n",
      "Answer: 부정\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_i = [0, 10, 50]\n",
    "sentiment = [\"긍정\", \"부정\", \"중립\"]\n",
    "for i in test_i:\n",
    "    x = X_test[i]\n",
    "    y = model.predict([x])[0]\n",
    "    print(data.loc[i])\n",
    "    print(\"Predict:\", sentiment[y])\n",
    "    print(\"Answer:\", sentiment[y_test.values[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 모델을 pickle 파일로 저장합니다.\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "t = datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "pickle.dump(model, open(f\"../model/tfidf_svm_{t}.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
